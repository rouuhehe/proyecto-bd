# PROYECTO BASE DE DATOS ğŸ’¯

## Estructura del proyecto
```
proyecto-bd
â”œâ”€â”€ .vscode
â”‚  â””â”€â”€ settings.json
â”œâ”€â”€ consultas
â”‚  â”œâ”€â”€ consulta_1.sql
â”‚  â”œâ”€â”€ consulta_2.sql
â”‚  â”œâ”€â”€ consulta_2_new.sql
â”‚  â”œâ”€â”€ consulta_3.sql
â”‚  â””â”€â”€ consulta_4.sql
â”œâ”€â”€ datos
â”‚  â”œâ”€â”€ cargar_100m.py
â”‚  â”œâ”€â”€ cargar_10m.py
â”‚  â”œâ”€â”€ cargar_1m.py
â”‚  â”œâ”€â”€ cargar_1MN.py
â”‚  â””â”€â”€ vacunas1millon.py
â”œâ”€â”€ DB
â”‚  â”œâ”€â”€ tablas
â”‚  â”‚  â”œâ”€â”€ tablas1
â”‚  â”‚  â”œâ”€â”€ tablas10
â”‚  â”‚  â”œâ”€â”€ tablas100
â”‚  â”‚  â”œâ”€â”€ tablasMillon
â”‚  â”‚  â””â”€â”€ exportar.py
â”‚  â”œâ”€â”€ .gitattributes
â”‚  â””â”€â”€ poblar.py
â”œâ”€â”€ readme-files
â”œâ”€â”€ resultados
â”œâ”€â”€ scripts
â”‚  â”œâ”€â”€ crear_tablas.sql
â”‚  â”œâ”€â”€ droptables.sql
â”‚  â””â”€â”€ limpiar_bd.sql
â”œâ”€â”€ .gitattributes
â””â”€â”€ README.md
```

## Cargar base de datos

Holi, grupo, asumiendo que ya tienen una base de datos creada, la manera en la que podrÃ¡n *"clonar"* la base de datos es la siguiente:

En la carpeta `DB` encontrarÃ¡n el archivo `poblar.py`, en donde tendrÃ¡n que configurar los datos de la base de datos que han creado en local.

```python
# === CONFIGURA ESTO ===
DB_NAME = "nombre-bd"
USER = "postgres"
PASSWORD = "postgres"
HOST = "localhost"
PORT = "5432" # lo configuraron al momento de instalar pgAdmin
CSV_PARENT_FOLDER = r"RUTA"
# =======================
```

En el apartado de `CSV_PARENT_FOLDER`, la ruta es la direcciÃ³n del directorio en donde se ecuentran las tablas con los datos.

Por ejemplo, dentro de la carpeta `tablas1` se encuentran los datos de la base de datos con 1000 datos (por tabla) y su ruta, en mi computadora, es algo asÃ­: 
- `DB\tablas\tablas10`
- `C:\Users\yarit\Documents\utec\2025-1\bd\proyecto\proyecto-bd\DB\tablas\tablas10`


## Crear base de datos

En caso quieran poblar la base de datos por su cuenta, en el archivo `crear_tablas.sql` encontrarÃ¡n el script para crear las tablas de la db. Si usan Visual Studio Code pueden instalar la extensiÃ³n de `SQLTools`, `SQLTools PostgreSQL/otras-cosas` y ejecutar el script directamente desde ahÃ­. En caso de que no tengan la extensiÃ³n, pueden copiar el script y pegarlo en el editor de consultas de pgAdmin.

## Generar e insertar datos

Para generar datos de prueba, usaremos la librerÃ­a `Faker` y `psycopg2` para conectarnos a la base de datos PostgreSQL. AsegÃºrense de tener instalado el paquete `Faker` y `psycopg2-binary`. Pueden instalarlo ejecutando el siguiente comando en su terminal:

```
pip install faker psycopg2-binary
```

Luego en el archivo de python, asegÃºrense de establecer la conexiÃ³n a la base de datos. AquÃ­ les dejo un ejemplo de cÃ³mo hacerlo (de todas formas en todos los archivos se encuentra esta cabecera, aun asÃ­, revisen el puerto):

```python
conn = psycopg2.connect(
    dbname="proyecto", # Nombre de la base de datos
    user="postgres", # Usuario de la base de datos
    password="postgres", # ContraseÃ±a del usuario
    host="localhost", 
    port="5433" # Puerto de la base de datos, lo configuraron en el pgAdmin
)
```

Una vez establecida la conexiÃ³n, pueden ejecutar el script `cargar_nDatos.py` para generar e insertar datos en las tablas. Este script generarÃ¡ datos de prueba para las tablas que utilizaremos en las consultas.

Pueden correr los scripts como mejor se les acomode.

## Eliminar datos
Si necesitan eliminar los datos de las tablas, pueden usar el script `eliminar_datos.sql` que se encuentra en el repositorio. Este script eliminarÃ¡ todos los datos de las tablas sin eliminar las tablas mismas.

# Acerca del enunciado

## Consideraciones

Se nos dice que debemos considerar que la **â€œexperimentacion**" y "**optimizacion**â€ debe realizarse mediante 2 o 3 consultas
â€œ**genericas**â€ con un **nivel aceptable de complejidad en las consultas propuestas**. 

Dichas consultas se deben realizar en cuatro contextos de 1000 (mil) datos, 10000 (diez mil) datos, 100000 (cien mil) datos y 1 000 000 (un millon) de datos almacenados en la base de datos (deberÄ±an tener 4 dumps de su proyecto).

---

Usaremos estas tres consultas como base para la comparaciÃ³n:
1. Â¿QuÃ© veterinarios han atendido la mayor cantidad de mascotas en el Ãºltimo mes?
2. Â¿CuÃ¡l es el tipo de tratamiento mÃ¡s comÃºn a perros en los Ãºltimos seis meses?
3. Â¿QuÃ© dÃ­a de la semana concentra el mayor nÃºmero de citas mÃ©dicas?


(Extra) Â¿Cual serÄ±a la complejidad operacional si escalamos los datos por encima del millon?,
realice una comparativa respecto a la cantidad de datos del p Ìarrafo anterior. Â¿Es suficiente la arquitectura Cliente-Servidor para procesar millones de datos?

